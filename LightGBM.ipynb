{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import keras \n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dowload_data_here.txt', 'submission_format.csv', 'test_labels.csv', 'test_values.csv', 'train_labels.csv', 'train_values.csv']\n"
     ]
    }
   ],
   "source": [
    "DIR  = \"data/\"\n",
    "SEED = 1881\n",
    "\n",
    "if not os.path.isdir(\"models/\"):\n",
    "    os.makedirs(\"models\")\n",
    "    \n",
    "print(os.listdir(DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(DIR+\"train_values.csv\")\n",
    "train_y = pd.read_csv(DIR+\"train_labels.csv\")\n",
    "test_x  = pd.read_csv(DIR+\"test_values.csv\")\n",
    "sub_csv = pd.read_csv(DIR+\"submission_format.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo1 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_1_id\"], test_x[\"geo_level_1_id\"]])))\n",
    "geo2 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_2_id\"], test_x[\"geo_level_2_id\"]])))\n",
    "geo3 = np.array(pd.get_dummies(pd.concat([train_x[\"geo_level_3_id\"], test_x[\"geo_level_3_id\"]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NET():\n",
    "    inp = Input((geo3.shape[1],))\n",
    "    i1 = Dense(16, name=\"intermediate\")(inp)\n",
    "    x2 = Dense(geo2.shape[1], activation='sigmoid')(i1)\n",
    "    x1 = Dense(geo1.shape[1], activation='sigmoid')(i1)\n",
    "\n",
    "    model = Model(inp, [x2,x1])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate deeper model did not give better results\n",
    "def NET():\n",
    "    inp = Input((geo3.shape[1],))\n",
    "    x = Dense(128, activation='relu')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x2 = Dense(geo2.shape[1], activation='sigmoid', name=\"output_2\")(x)\n",
    "    x1 = Dense(geo1.shape[1], activation='sigmoid', name=\"output_1\")(x)\n",
    "\n",
    "    model = Model(inp, [x2,x1])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10859/10859 - 358s - loss: 0.0932 - dense_2_loss: 0.0172 - dense_3_loss: 0.0760 - 358s/epoch - 33ms/step\n",
      "Epoch 2/10\n",
      "10859/10859 - 357s - loss: 0.0072 - dense_2_loss: 0.0031 - dense_3_loss: 0.0041 - 357s/epoch - 33ms/step\n",
      "Epoch 3/10\n",
      "10859/10859 - 354s - loss: 0.0025 - dense_2_loss: 0.0016 - dense_3_loss: 9.3608e-04 - 354s/epoch - 33ms/step\n",
      "Epoch 4/10\n",
      "10859/10859 - 361s - loss: 0.0010 - dense_2_loss: 6.7001e-04 - dense_3_loss: 3.5547e-04 - 361s/epoch - 33ms/step\n",
      "Epoch 5/10\n",
      "10859/10859 - 358s - loss: 4.9443e-04 - dense_2_loss: 3.4887e-04 - dense_3_loss: 1.4556e-04 - 358s/epoch - 33ms/step\n",
      "Epoch 6/10\n",
      "10859/10859 - 353s - loss: 2.8026e-04 - dense_2_loss: 2.2095e-04 - dense_3_loss: 5.9311e-05 - 353s/epoch - 33ms/step\n",
      "Epoch 7/10\n",
      "10859/10859 - 359s - loss: 1.8151e-04 - dense_2_loss: 1.5691e-04 - dense_3_loss: 2.4607e-05 - 359s/epoch - 33ms/step\n",
      "Epoch 8/10\n",
      "10859/10859 - 356s - loss: 1.3003e-04 - dense_2_loss: 1.1958e-04 - dense_3_loss: 1.0442e-05 - 356s/epoch - 33ms/step\n",
      "Epoch 9/10\n",
      "10859/10859 - 351s - loss: 9.9141e-05 - dense_2_loss: 9.4507e-05 - dense_3_loss: 4.6339e-06 - 351s/epoch - 32ms/step\n",
      "Epoch 10/10\n",
      "10859/10859 - 350s - loss: 7.8265e-05 - dense_2_loss: 7.6116e-05 - dense_3_loss: 2.1487e-06 - 350s/epoch - 32ms/step\n"
     ]
    }
   ],
   "source": [
    "model = NET()\n",
    "model.fit(geo3, [geo2, geo1], batch_size=32, epochs=10, verbose=2)\n",
    "model.save(\"geo_embed.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NET()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "get_int_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[1].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for dat in geo3[:260601]:\n",
    "    layer_output = get_int_layer_output([np.reshape(dat, (1, geo3.shape[1]))])[0]\n",
    "    out.append(layer_output)\n",
    "\n",
    "out = np.array(out)\n",
    "out = np.squeeze(out)\n",
    "\n",
    "train_data = pd.get_dummies(train_x.copy())\n",
    "train_data = train_data.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "train_data = train_data.assign(geo_feat1=out[:,0],\n",
    "                               geo_feat2=out[:,1],\n",
    "                               geo_feat3=out[:,2],  \n",
    "                               geo_feat4=out[:,3],\n",
    "                               geo_feat5=out[:,4],    \n",
    "                               geo_feat6=out[:,5],\n",
    "                               geo_feat7=out[:,6],\n",
    "                               geo_feat8=out[:,7],\n",
    "                               geo_feat9=out[:,8],\n",
    "                               geo_feat10=out[:,9],\n",
    "                               geo_feat11=out[:,10],\n",
    "                               geo_feat12=out[:,11],\n",
    "                               geo_feat13=out[:,12],\n",
    "                               geo_feat14=out[:,13],\n",
    "                               geo_feat15=out[:,14],           \n",
    "                               geo_feat16=out[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for dat in geo3[260601:]:\n",
    "    layer_output = get_int_layer_output([np.reshape(dat, (1, geo3.shape[1]))])[0]\n",
    "    out.append(layer_output)\n",
    "\n",
    "out = np.array(out)\n",
    "out = np.squeeze(out)\n",
    "\n",
    "test_data = pd.get_dummies(test_x.copy())\n",
    "test_data = test_data.drop(['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id'], axis=1)\n",
    "test_data = test_data.assign(geo_feat1=out[:,0],\n",
    "                            geo_feat2=out[:,1],\n",
    "                            geo_feat3=out[:,2],  \n",
    "                            geo_feat4=out[:,3],\n",
    "                            geo_feat5=out[:,4],    \n",
    "                            geo_feat6=out[:,5],\n",
    "                            geo_feat7=out[:,6],\n",
    "                            geo_feat8=out[:,7],\n",
    "                            geo_feat9=out[:,8],\n",
    "                            geo_feat10=out[:,9],\n",
    "                            geo_feat11=out[:,10],\n",
    "                            geo_feat12=out[:,11],\n",
    "                            geo_feat13=out[:,12],\n",
    "                            geo_feat14=out[:,13],\n",
    "                            geo_feat15=out[:,14],           \n",
    "                            geo_feat16=out[:,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_arr(array):\n",
    "    new_arr = []\n",
    "    for ix, val in enumerate(array):\n",
    "        loc = np.array(val).argmax(axis=0)\n",
    "        k = list(np.zeros((len(val))))\n",
    "        k[loc]=1\n",
    "        new_arr.append(k)\n",
    "        \n",
    "    return np.array(new_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(train_y[\"damage_grade\"])-1\n",
    "\n",
    "df = train_data.drop([\"building_id\"], axis=1)\n",
    "x = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043605 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122908\n",
      "[LightGBM] [Info] Number of data points in the train set: 208480, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -2.339173\n",
      "[LightGBM] [Info] Start training from score -0.564028\n",
      "[LightGBM] [Info] Start training from score -1.094582\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.25696\n",
      "[2000]\tvalid_0's multi_error: 0.253909\n",
      "[3000]\tvalid_0's multi_error: 0.254485\n",
      "[4000]\tvalid_0's multi_error: 0.255406\n",
      "[5000]\tvalid_0's multi_error: 0.257497\n",
      "Early stopping, best iteration is:\n",
      "[2091]\tvalid_0's multi_error: 0.253353\n",
      "F1-MICRO SCORE:  0.7466472247270773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122803\n",
      "[LightGBM] [Info] Number of data points in the train set: 208481, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.339128\n",
      "[LightGBM] [Info] Start training from score -0.564032\n",
      "[LightGBM] [Info] Start training from score -1.094586\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.259094\n",
      "[2000]\tvalid_0's multi_error: 0.255814\n",
      "[3000]\tvalid_0's multi_error: 0.255065\n",
      "[4000]\tvalid_0's multi_error: 0.256216\n",
      "[5000]\tvalid_0's multi_error: 0.258001\n",
      "[6000]\tvalid_0's multi_error: 0.259823\n",
      "Early stopping, best iteration is:\n",
      "[3182]\tvalid_0's multi_error: 0.254375\n",
      "F1-MICRO SCORE:  0.7456254796623177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122967\n",
      "[LightGBM] [Info] Number of data points in the train set: 208481, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -2.339178\n",
      "[LightGBM] [Info] Start training from score -0.564024\n",
      "[LightGBM] [Info] Start training from score -1.094586\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.255468\n",
      "[2000]\tvalid_0's multi_error: 0.252379\n",
      "[3000]\tvalid_0's multi_error: 0.253837\n",
      "[4000]\tvalid_0's multi_error: 0.25447\n",
      "Early stopping, best iteration is:\n",
      "[1361]\tvalid_0's multi_error: 0.251727\n",
      "F1-MICRO SCORE:  0.7482732156561781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.059469 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122909\n",
      "[LightGBM] [Info] Number of data points in the train set: 208481, number of used features: 80\n",
      "[LightGBM] [Info] Start training from score -2.339178\n",
      "[LightGBM] [Info] Start training from score -0.564032\n",
      "[LightGBM] [Info] Start training from score -1.094572\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.256581\n",
      "[2000]\tvalid_0's multi_error: 0.253454\n",
      "[3000]\tvalid_0's multi_error: 0.253185\n",
      "[4000]\tvalid_0's multi_error: 0.254624\n",
      "[5000]\tvalid_0's multi_error: 0.255602\n",
      "Early stopping, best iteration is:\n",
      "[2735]\tvalid_0's multi_error: 0.252456\n",
      "F1-MICRO SCORE:  0.747544128933231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\Users\\jehil\\OneDrive\\Documents\\GitHub\\richter-predictor\\.conda\\lib\\site-packages\\lightgbm\\engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045900 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 122953\n",
      "[LightGBM] [Info] Number of data points in the train set: 208481, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score -2.339178\n",
      "[LightGBM] [Info] Start training from score -0.564032\n",
      "[LightGBM] [Info] Start training from score -1.094572\n",
      "Training until validation scores don't improve for 3000 rounds\n",
      "[1000]\tvalid_0's multi_error: 0.257118\n",
      "[2000]\tvalid_0's multi_error: 0.253665\n",
      "[3000]\tvalid_0's multi_error: 0.254029\n",
      "[4000]\tvalid_0's multi_error: 0.255142\n",
      "[5000]\tvalid_0's multi_error: 0.257022\n",
      "Early stopping, best iteration is:\n",
      "[2815]\tvalid_0's multi_error: 0.253089\n",
      "F1-MICRO SCORE:  0.7469109746738296\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "for ix, (train_index, test_index) in enumerate(kf.split(x, y)):\n",
    "    lgb_params = {\n",
    "        \"objective\" : \"multiclass\",\n",
    "        \"num_class\":3,\n",
    "        \"metric\" : \"multi_error\",\n",
    "        \"boosting\": 'gbdt',\n",
    "        \"max_depth\" : -1,\n",
    "        \"num_leaves\" : 30,\n",
    "        \"learning_rate\" : 0.1,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"min_sum_hessian_in_leaf\" : 0.1,\n",
    "        \"max_bin\":8192,\n",
    "        \"verbosity\" : 1,\n",
    "        \"num_threads\":6,\n",
    "        \"seed\": SEED\n",
    "    }\n",
    "\n",
    "    x_train, x_val, y_train, y_val= x[train_index], x[test_index], y[train_index], y[test_index]\n",
    "\n",
    "    train_data = lgb.Dataset(x_train, label=y_train)\n",
    "    val_data   = lgb.Dataset(x_val, label=y_val)\n",
    "\n",
    "    lgb_clf = lgb.train(lgb_params,\n",
    "                        train_data,\n",
    "                        20000,\n",
    "                        valid_sets = [val_data],\n",
    "                        early_stopping_rounds=3000,\n",
    "                        verbose_eval = 1000)\n",
    "\n",
    "    y_pred = lgb_clf.predict(x_val)\n",
    "    print(\"F1-MICRO SCORE: \", f1_score(np.array(pd.get_dummies(y_val)), threshold_arr(y_pred), average='micro'))\n",
    "    lgb_clf.save_model(f'models/model{ix}.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-MICRO SCORE:  0.8178978591793585\n",
      "F1-MICRO SCORE:  0.8413091277470156\n",
      "F1-MICRO SCORE:  0.7971535028645323\n",
      "F1-MICRO SCORE:  0.8322953480608286\n",
      "F1-MICRO SCORE:  0.8345862064995914\n"
     ]
    }
   ],
   "source": [
    "# Load all LightGB Models and concatenate.\n",
    "models = []\n",
    "for i in range(5):\n",
    "    model = lgb.Booster(model_file=f'models/model{i}.txt')\n",
    "\n",
    "    y_pred = model.predict(x)\n",
    "    score  = f1_score(np.array(pd.get_dummies(y)), threshold_arr(y_pred), average='micro')\n",
    "    print(\"F1-MICRO SCORE: \", score)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(models, x):\n",
    "    # Ensemble K-Fold CV models with adding all confidence score by class.\n",
    "    y_preds = []\n",
    "    \n",
    "    for model in models:\n",
    "        y_pred = model.predict(x)\n",
    "        y_preds.append(y_pred)\n",
    "        \n",
    "    init_y_pred = y_preds[0]\n",
    "    for ypred in y_preds[1:]:\n",
    "        init_y_pred += ypred\n",
    "        \n",
    "    y_pred = threshold_arr(init_y_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86868, 39)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test_data.drop([\"building_id\"], axis=1)\n",
    "x = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble(models, x)\n",
    "y_pred = y_pred.argmax(axis=1)+1\n",
    "sub_csv[\"damage_grade\"] = y_pred\n",
    "sub_csv.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
